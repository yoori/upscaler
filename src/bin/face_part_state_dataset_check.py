import argparse
import pathlib
import random

import cv2
import numpy as np
import torch

from upscaler.face_part_state_dataset import FacePartStateDataset, PARTS, STATES


def _build_parser() -> argparse.ArgumentParser:
  parser = argparse.ArgumentParser(
    description="Save samples generated by FacePartStateDataset for visual QA.",
  )
  parser.add_argument("--images-dir", type=pathlib.Path, required=True, help="Directory with source photos")
  parser.add_argument("--output-dir", type=pathlib.Path, required=True, help="Directory to save generated samples")
  parser.add_argument("-n", type=int, default=30, help="How many dataset samples to save")
  parser.add_argument("--device", default="cuda" if torch.cuda.is_available() else "cpu")
  parser.add_argument("--face-size", type=int, default=512)
  parser.add_argument("--image-size", type=int, default=224)
  parser.add_argument("--repeat", type=int, default=3)
  parser.add_argument("--blur-probability", type=float, default=0.8)
  parser.add_argument("--occlusion-probability", type=float, default=0.1)
  parser.add_argument("--uncertain-probability", type=float, default=0.1)
  parser.add_argument("--seed", type=int, default=42)
  return parser


def _tensor_to_bgr_image(image_tensor: torch.Tensor) -> np.ndarray:
  image = image_tensor.detach().cpu().numpy().transpose(1, 2, 0)
  image = ((image * 0.5) + 0.5) * 255.0
  image = np.clip(image, 0, 255).astype(np.uint8)
  return cv2.cvtColor(image, cv2.COLOR_RGB2BGR)


def _unique_output_path(output_dir: pathlib.Path, base_name: str) -> pathlib.Path:
  candidate = output_dir / f"{base_name}.jpg"
  if not candidate.exists():
    return candidate

  suffix = 1
  while True:
    candidate = output_dir / f"{base_name}_{suffix}.jpg"
    if not candidate.exists():
      return candidate
    suffix += 1


def main() -> int:
  parser = _build_parser()
  args = parser.parse_args()

  if args.n <= 0:
    parser.error("-n must be positive")
  if not args.images_dir.is_dir():
    parser.error(f"Images directory not found: {args.images_dir}")

  dataset = FacePartStateDataset(
    images_dir=args.images_dir,
    device=args.device,
    face_size=args.face_size,
    image_size=args.image_size,
    repeat=args.repeat,
    blur_probability=args.blur_probability,
    occlusion_probability=args.occlusion_probability,
    uncertain_probability=args.uncertain_probability,
    seed=args.seed,
  )

  args.output_dir.mkdir(parents=True, exist_ok=True)
  samples_to_save = min(args.n, len(dataset))

  for index in range(samples_to_save):
    image_tensor, _, part_tensor, state_tensor = dataset[index]
    meta, _ = dataset.samples[index]

    part_name = PARTS[int(part_tensor.item())]
    state_name = STATES[int(state_tensor.item())]
    original_name = meta.image_path.stem

    out_path = _unique_output_path(args.output_dir, f"{original_name}_{part_name}_{state_name}")
    image_bgr = _tensor_to_bgr_image(image_tensor)
    cv2.imwrite(str(out_path), image_bgr)

  print(f"Saved {samples_to_save} samples to: {args.output_dir}")
  return 0


if __name__ == "__main__":
  random.seed()
  raise SystemExit(main())
